{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting and cleaning the MAC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get macc data and imports\n",
    "from wrangle import get_mac_data\n",
    "import pandas as pd\n",
    "from prepare_module import summarize\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mac data\n",
    "df = get_mac_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "* nulls:\n",
    "    * **CLOSEDDATE**: expected, implies that they ar not closed, will invesitgate to ensure there aren't any errors\n",
    "    * **TOWNSHIP__C**: investigate why, may need some domain knowledge about indianapolis metro area townships, where they lie \n",
    "    * [indy gis township information](https://data.indy.gov/datasets/75f6558b7a074edb8fa5fa9b0d1fc867/explore)\n",
    "    * [townships throughout the state](https://www.stats.indiana.edu/maptools/maps/boundary/townships_2000/townships_statewide.pdf)\n",
    "    * **COUNCIL_DISTRICT__C**: investigate why, I think there may be a connection with the council districts nulls and the township nulls \n",
    "        * Note: there may be council redistricting and township redistrictinhg that may be impacting this \n",
    "    * **SOURCE_ID**: what is the source id in the first place? id it necessary for the analysis? What the the source Id correspond with? is each source id unique or are they connected to something meaningful?\n",
    "    * **CITY__C**: The city can be found by plotting the address on a map.\n",
    "        1. Find out if python has something for addresses in the united states\n",
    "        1. If not, get the geometries for eact objectid\n",
    "        1. Get the geometries for cities in indiana\n",
    "        1. Find out where each objectid geometry falls and fill in the CITY__C nulls with the new data\n",
    "* Features/Variables:\n",
    "    * ORIGIN: see if there is a relationship between origin and the time a service case is handled\n",
    "    * STATUS:\n",
    "        * Question: What proportion of each *category* is open/closed?\n",
    "        * Question: What proportion of each *city* is open/closed?\n",
    "        * Question: What proportion of each *township* is open/closed?\n",
    "        * Question: What proportion of each *council district* is open/closed?\n",
    "        * Question: What proportion of each *zip code* is open/closed?\n",
    "    * Dates:\n",
    "        * CLOSEDDATE: \n",
    "            * What are some reasons for the closed dates having (over 100) on one second? Is there a system wide update that occurs?\n",
    "            * Is there a connection between the createddate and the closeddate?\n",
    "        * CREATEDDATE: \n",
    "            * Why are there mulitple CREATEDDATE entries with the same second? Are there multiple categories of service frequests oin one call that are all inputed? Are these duplicates?\n",
    "    * COUNCIL_DISTRICT__C\n",
    "        * See how many districts there are and which districts have the best response times and worst response times\n",
    "    * ZIP__C\n",
    "        1. Make sure this is the zip code\n",
    "        1. Get a csv file with the zipcode geometries in the states of indiana\n",
    "        1. Merge the csv file with this data using the zipcode as the point of merging\n",
    "        1. Use this to create a map of who has good time, who has bad response time, and whjo has great response times\n",
    "     * CITY__C : \n",
    "        1. Change indianapolisq mispelling\n",
    "        1. Investigate the 'NONE'\n",
    "        1. Determine which has the fastest turnaround for non-emergency calls\n",
    "        1. Does the Mayor Action thing apply to the other cities??\n",
    "    * INCIDENT_ADDRESS__C\n",
    "        * See if we can plot the incident addresses and identify the city for each \n",
    "        * Check to see whay some incidetn addressess have so many counts int he data\n",
    "    * SUBCATEGORY__C:\n",
    "        * Consolidate subcategories\n",
    "        * If after consolidation , place all low couont subcategories into a new subcaegory called 'low_count_subcategories'\n",
    "    * KEYWORD__C:\n",
    "        1. Order all the key words alphabetically to check for duplicateswith similar spelling, see if it is intentional\n",
    "        1. Within duplicates, ensure the subcategories are similary to the duplucatedones\n",
    "    * SOURCE_ID__C\n",
    "        * not very clear how this works. is there a list of source_id signifieers or a key that shows the meaning and significance of this information?\n",
    "    * CASENUMBER:\n",
    "        * Whya re there duplicate case numbers?\n",
    "\n",
    "\n",
    "#### Actions:\n",
    "* nulls:\n",
    "    * CLOSEDDATE: Initially, I will fill all the closeddates with a number far out into the future that is not possible to represent unclosed\n",
    "    *  I will drop all nulls for now and later go and fill in the missing information with other data sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing nulls and changing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# change columsn names to lower, remove the __c and that's it\n",
    "col_rename = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    col_rename[col] = col.lower().replace('__c', '')\n",
    "\n",
    "df.rename(col_rename, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'keyword', 'subcategory', 'incident_address', 'township',\n",
      "       'city', 'zip', 'council_district', 'createddate', 'lastmodifieddate',\n",
      "       'closeddate', 'status', 'origin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot mix tz-aware with tz-naive values, at position 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# changing multiple columns to date time dtype\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m----> 4\u001b[0m df[[\u001b[39m'\u001b[39m\u001b[39mcreateddate\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlastmodifieddate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcloseddate\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39;49m\u001b[39mcreateddate\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mlastmodifieddate\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcloseddate\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39;49mapply(pd\u001b[39m.\u001b[39;49mto_datetime)\n\u001b[1;32m      6\u001b[0m df\u001b[39m.\u001b[39mdtypes\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1050\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1049\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1050\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[1;32m   1051\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1052\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:455\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 455\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    456\u001b[0m     arg,\n\u001b[1;32m    457\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[1;32m    458\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[1;32m    459\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[1;32m    460\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    461\u001b[0m     allow_object\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray(result, dtype\u001b[39m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[39m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mobject_)\n\u001b[0;32m-> 2177\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39;49marray_to_datetime(\n\u001b[1;32m   2178\u001b[0m     data,\n\u001b[1;32m   2179\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   2180\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[1;32m   2181\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[1;32m   2182\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[1;32m   2183\u001b[0m )\n\u001b[1;32m   2185\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2186\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m     \u001b[39m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2188\u001b[0m     \u001b[39m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:402\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:479\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/codeup-data-science/env/lib/python3.9/site-packages/pandas/_libs/tslibs/conversion.pyx:734\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_timezone\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot mix tz-aware with tz-naive values, at position 15"
     ]
    }
   ],
   "source": [
    "# changing multiple columns to date time dtype\n",
    "print(df.columns)\n",
    "\n",
    "df[['createddate','lastmodifieddate', 'closeddate']] = df[['createddate','lastmodifieddate', 'closeddate']].apply(pd.to_datetime)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the closeddate nulls to a date that hasnt come\n",
    "df[df.closeddate.isna() == True]\n",
    "\n",
    "df.closeddate.fillna('9999',  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closeddate\n",
       "2018-05-01 16:32:02+00:00    200\n",
       "2018-05-01 16:32:45+00:00    200\n",
       "2015-11-09 12:26:20+00:00    188\n",
       "2018-05-01 16:33:35+00:00    164\n",
       "2018-05-01 16:32:55+00:00    142\n",
       "                            ... \n",
       "2021-11-17 12:37:13+00:00      1\n",
       "2021-12-06 17:07:37+00:00      1\n",
       "2021-11-16 20:37:06+00:00      1\n",
       "2021-11-29 19:57:33+00:00      1\n",
       "2020-11-13 03:42:20+00:00      1\n",
       "Name: count, Length: 883366, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.closeddate.value_counts()\n",
    "\n",
    "pd.to_datetime(df.closeddate, errors='coerce').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closeddate\n",
       "9999-12-31                   35107\n",
       "2018-05-01 16:32:45+00:00      200\n",
       "2018-05-01 16:32:02+00:00      200\n",
       "2015-11-09 12:26:20+00:00      188\n",
       "2018-05-01 16:33:35+00:00      164\n",
       "                             ...  \n",
       "2021-11-17 12:37:13+00:00        1\n",
       "2021-12-06 17:07:37+00:00        1\n",
       "2021-11-16 20:37:06+00:00        1\n",
       "2021-11-29 19:57:33+00:00        1\n",
       "2020-11-13 03:42:20+00:00        1\n",
       "Name: count, Length: 883367, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.closeddate[df.closeddate == '9999'] = '9999-12-31'\n",
    "\n",
    "df.closeddate.value_counts()\n",
    "\n",
    "# df.closeddate.apply(pd.to_datetime) An error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "found a solution here [here](https://www.statology.org/pandas-out-of-bounds-nanosecond-timestamp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closeddate\n",
       "2262-04-11 23:47:16.854775807    35107\n",
       "2018-05-01 16:32:45+00:00          200\n",
       "2018-05-01 16:32:02+00:00          200\n",
       "2015-11-09 12:26:20+00:00          188\n",
       "2018-05-01 16:33:35+00:00          164\n",
       "                                 ...  \n",
       "2021-11-17 12:37:13+00:00            1\n",
       "2021-12-06 17:07:37+00:00            1\n",
       "2021-11-16 20:37:06+00:00            1\n",
       "2021-11-29 19:57:33+00:00            1\n",
       "2020-11-13 03:42:20+00:00            1\n",
       "Name: count, Length: 883367, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.closeddate[df.closeddate == '9999-12-31'] = pd.Timestamp.max\n",
    "\n",
    "df.closeddate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 24008 rows when dropping the nulls\n"
     ]
    }
   ],
   "source": [
    "# dropping all other nulls in the ds\n",
    "print(f'Dropping {df.shape[0] -  df.dropna().shape[0]} rows when dropping the nulls')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Open    35107\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# closseddate invesigation\n",
    "close_date_null = df[df['closeddate'].isna() == True] # getting the df\n",
    "\n",
    "# looking at the statuses, if the status is cklosed and there is no closeddate then there is an issue\n",
    "close_date_null['status'].value_counts() # all of the nulls in this section are open which is to be expected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the township null segments\n",
    "summarize(df[df['township'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping uneccessary columns and adding the time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OBJECTID': 'objectid', 'CASENUMBER': 'casenumber', 'SOURCE_ID__C': 'source_id', 'KEYWORD__C': 'keyword', 'SUBCATEGORY__C': 'subcategory', 'INCIDENT_ADDRESS__C': 'incident_address', 'TOWNSHIP__C': 'township', 'CITY__C': 'city', 'ZIP__C': 'zip', 'COUNCIL_DISTRICT__C': 'council_district', 'CREATEDDATE': 'created', 'LASTMODIFIEDDATE': 'last_modified', 'CLOSEDDATE': 'closed', 'STATUS': 'status', 'ORIGIN': 'origin'}\n"
     ]
    }
   ],
   "source": [
    "df = get_mac_data()\n",
    "\n",
    "# change columsn names to lower, remove the __c and that's it\n",
    "col_rename = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    col_rename[col] = col.lower().replace('__c', '').replace('date', '')\n",
    "\n",
    "col_rename['LASTMODIFIEDDATE'] = 'last_modified'\n",
    "\n",
    "df.rename(col_rename, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2262-03-31 00:00:00-0500', tz='US/Eastern')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution to out of bound and tz naive/tz aware discrepancy\n",
    "pd.Timestamp.max.floor('30D').tz_localize('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>township</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>council_district</th>\n",
       "      <th>createddate</th>\n",
       "      <th>lastmodifieddate</th>\n",
       "      <th>closeddate</th>\n",
       "      <th>status</th>\n",
       "      <th>origin</th>\n",
       "      <th>close_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INV22-01609</td>\n",
       "      <td>Illegal Dumping and Junk/Trash</td>\n",
       "      <td>Trash Accumulation or Dumped Materials</td>\n",
       "      <td>1142 N GOODLET AVE</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2022-01-31 15:25:28+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>RequestIndy Mobile</td>\n",
       "      <td>0 days 22:33:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22-375189</td>\n",
       "      <td>Animal</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>3501 RALSTON AVE</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46218</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-01-28 18:35:54+00:00</td>\n",
       "      <td>2022-01-29 03:43:27+00:00</td>\n",
       "      <td>2022-01-29 03:43:20+00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0 days 09:07:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108343054</td>\n",
       "      <td>Trash</td>\n",
       "      <td>96 Gal Cart - Stolen</td>\n",
       "      <td>1102 N PARKER AVE</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46201</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2022-01-28 21:12:49+00:00</td>\n",
       "      <td>2022-03-21 14:07:36+00:00</td>\n",
       "      <td>2022-03-21 14:07:36+00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Phone</td>\n",
       "      <td>51 days 16:54:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email Sent</td>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>Street/Alley (ABV)</td>\n",
       "      <td>4631 ROSSLYN AVE</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46205</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-01-30 21:23:42+00:00</td>\n",
       "      <td>2022-02-03 21:29:59+00:00</td>\n",
       "      <td>2022-02-03 21:29:59+00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>RequestIndy Online</td>\n",
       "      <td>4 days 00:06:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108343404</td>\n",
       "      <td>Trash</td>\n",
       "      <td>96 Gal Trash (Missed)</td>\n",
       "      <td>4360 SAWYER AVE</td>\n",
       "      <td>LAWRENCE</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46226</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2022-01-31 15:44:58+00:00</td>\n",
       "      <td>2022-01-31 16:37:08+00:00</td>\n",
       "      <td>2022-01-31 16:37:08+00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>RequestIndy Online</td>\n",
       "      <td>0 days 00:52:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source_id                         keyword  \\\n",
       "0  INV22-01609  Illegal Dumping and Junk/Trash   \n",
       "1   A22-375189                          Animal   \n",
       "2    108343054                           Trash   \n",
       "3   Email Sent               Abandoned Vehicle   \n",
       "4    108343404                           Trash   \n",
       "\n",
       "                              subcategory    incident_address    township  \\\n",
       "0  Trash Accumulation or Dumped Materials  1142 N GOODLET AVE       WAYNE   \n",
       "1                                   Abuse    3501 RALSTON AVE      CENTER   \n",
       "2                    96 Gal Cart - Stolen   1102 N PARKER AVE      CENTER   \n",
       "3                      Street/Alley (ABV)    4631 ROSSLYN AVE  WASHINGTON   \n",
       "4                   96 Gal Trash (Missed)     4360 SAWYER AVE    LAWRENCE   \n",
       "\n",
       "           city    zip  council_district               createddate  \\\n",
       "0  INDIANAPOLIS  46222              11.0 2022-01-31 15:25:28+00:00   \n",
       "1  INDIANAPOLIS  46218               9.0 2022-01-28 18:35:54+00:00   \n",
       "2  INDIANAPOLIS  46201              17.0 2022-01-28 21:12:49+00:00   \n",
       "3  INDIANAPOLIS  46205               9.0 2022-01-30 21:23:42+00:00   \n",
       "4  INDIANAPOLIS  46226              13.0 2022-01-31 15:44:58+00:00   \n",
       "\n",
       "           lastmodifieddate                closeddate  status  \\\n",
       "0 2022-02-01 13:59:02+00:00 2022-02-01 13:59:02+00:00  Closed   \n",
       "1 2022-01-29 03:43:27+00:00 2022-01-29 03:43:20+00:00  Closed   \n",
       "2 2022-03-21 14:07:36+00:00 2022-03-21 14:07:36+00:00  Closed   \n",
       "3 2022-02-03 21:29:59+00:00 2022-02-03 21:29:59+00:00  Closed   \n",
       "4 2022-01-31 16:37:08+00:00 2022-01-31 16:37:08+00:00  Closed   \n",
       "\n",
       "               origin       close_time  \n",
       "0  RequestIndy Mobile  0 days 22:33:34  \n",
       "1               Phone  0 days 09:07:26  \n",
       "2               Phone 51 days 16:54:47  \n",
       "3  RequestIndy Online  4 days 00:06:17  \n",
       "4  RequestIndy Online  0 days 00:52:10  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['createddate','lastmodifieddate', 'closeddate']] = df[['createddate','lastmodifieddate', 'closeddate']].apply(pd.to_datetime)\n",
    "\n",
    "df['close_time'] = df['closeddate'] - df['createddate']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['createddate']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding the mac data using geopandas\n",
    "> **Resources:**\n",
    "> * [Guidance used](https://autogis-site.readthedocs.io/en/2019/notebooks/L3/geocoding_in_geopandas.html)\n",
    "> * [Geopy Documentation](https://geopy.readthedocs.io/en/stable/#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 24008 rows\n"
     ]
    }
   ],
   "source": [
    "# getting the clean mac data\n",
    "df = clean_mac_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtting only the addresses\n",
    "print(df.columns)\n",
    "\n",
    "# getting geocode format addresses\n",
    "df['full_address'] = df['incident_address'] + ' ' +  df['city'] + ' ' + df['state'] + ' ' + df['zip'].astype(str)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting geocode tool\n",
    "from geopandas.tools import geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-86.13089 39.81994)</td>\n",
       "      <td>3501, Ralston Avenue, Indianapolis, Marion Cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     geometry  \\\n",
       "0  POINT (-86.13089 39.81994)   \n",
       "\n",
       "                                             address  \n",
       "0  3501, Ralston Avenue, Indianapolis, Marion Cou...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a small batch to try it out first\n",
    "geo = geocode(df.iloc[1]['full_address'], provider='Nominatim', user_agent='indy_action_time', timeout=10)\n",
    "geo\n",
    "# success, but now we need to set it up for all of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Limiter using geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a smaller df to see if it works well\n",
    "temp = pd.DataFrame(df.iloc[:5].loc[:,'full_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('1142 N GOODLET AVE INDIANAPOLIS IN 46222',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('1142 N GOODLET AVE INDIANAPOLIS IN 46222',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1142+N+GOODLET+AVE+INDIANAPOLIS+IN+46222&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1142+N+GOODLET+AVE+INDIANAPOLIS+IN+46222&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1142+N+GOODLET+AVE+INDIANAPOLIS+IN+46222&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('1142 N GOODLET AVE INDIANAPOLIS IN 46222',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1142+N+GOODLET+AVE+INDIANAPOLIS+IN+46222&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1142+N+GOODLET+AVE+INDIANAPOLIS+IN+46222&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1142+N+GOODLET+AVE+INDIANAPOLIS+IN+46222&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('3501 RALSTON AVE INDIANAPOLIS IN 46218',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('3501 RALSTON AVE INDIANAPOLIS IN 46218',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=3501+RALSTON+AVE+INDIANAPOLIS+IN+46218&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=3501+RALSTON+AVE+INDIANAPOLIS+IN+46218&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=3501+RALSTON+AVE+INDIANAPOLIS+IN+46218&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('3501 RALSTON AVE INDIANAPOLIS IN 46218',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('1102 N PARKER AVE INDIANAPOLIS IN 46201',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('1102 N PARKER AVE INDIANAPOLIS IN 46201',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1102+N+PARKER+AVE+INDIANAPOLIS+IN+46201&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1102+N+PARKER+AVE+INDIANAPOLIS+IN+46201&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1102+N+PARKER+AVE+INDIANAPOLIS+IN+46201&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('1102 N PARKER AVE INDIANAPOLIS IN 46201',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1102+N+PARKER+AVE+INDIANAPOLIS+IN+46201&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1102+N+PARKER+AVE+INDIANAPOLIS+IN+46201&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1102+N+PARKER+AVE+INDIANAPOLIS+IN+46201&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('4631 ROSSLYN AVE INDIANAPOLIS IN 46205',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4631+ROSSLYN+AVE+INDIANAPOLIS+IN+46205&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4631+ROSSLYN+AVE+INDIANAPOLIS+IN+46205&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4631+ROSSLYN+AVE+INDIANAPOLIS+IN+46205&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('4631 ROSSLYN AVE INDIANAPOLIS IN 46205',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('4631 ROSSLYN AVE INDIANAPOLIS IN 46205',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4631+ROSSLYN+AVE+INDIANAPOLIS+IN+46205&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4631+ROSSLYN+AVE+INDIANAPOLIS+IN+46205&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4631+ROSSLYN+AVE+INDIANAPOLIS+IN+46205&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('4360 SAWYER AVE INDIANAPOLIS IN 46226',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('4360 SAWYER AVE INDIANAPOLIS IN 46226',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 475, in _request\n",
      "    raise AdapterHTTPError(\n",
      "geopy.adapters.AdapterHTTPError: Non-successful status code 502\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 388, in _call_geocoder\n",
      "    res = self._adapter_error_handler(error)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 411, in _adapter_error_handler\n",
      "    raise exc_cls(str(error)) from error\n",
      "geopy.exc.GeocoderServiceError: Non-successful status code 502\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('4360 SAWYER AVE INDIANAPOLIS IN 46226',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4360+SAWYER+AVE+INDIANAPOLIS+IN+46226&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 457, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4360+SAWYER+AVE+INDIANAPOLIS+IN+46226&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 447, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/aaron/codeup-data-science/env/lib/python3.9/site-packages/geopy/adapters.py\", line 469, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=4360+SAWYER+AVE+INDIANAPOLIS+IN+46226&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    }
   ],
   "source": [
    "# initiate geocoder \n",
    "geolocator = Nominatim(user_agent='indy_action_time')\n",
    "\n",
    "# create a geopy rate limite:\n",
    "geocode_with_delay = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# apply the geocoder with delay using the rate limiter\n",
    "temp['temp'] = temp['full_address'].apply(geocode_with_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_address</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1142 N GOODLET AVE INDIANAPOLIS IN 46222</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3501 RALSTON AVE INDIANAPOLIS IN 46218</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102 N PARKER AVE INDIANAPOLIS IN 46201</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4631 ROSSLYN AVE INDIANAPOLIS IN 46205</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4360 SAWYER AVE INDIANAPOLIS IN 46226</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               full_address  temp\n",
       "0  1142 N GOODLET AVE INDIANAPOLIS IN 46222  None\n",
       "1    3501 RALSTON AVE INDIANAPOLIS IN 46218  None\n",
       "2   1102 N PARKER AVE INDIANAPOLIS IN 46201  None\n",
       "3    4631 ROSSLYN AVE INDIANAPOLIS IN 46205  None\n",
       "4     4360 SAWYER AVE INDIANAPOLIS IN 46226  None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additions to the function based on explore \n",
    "* Changing the close time for open requests to todays date plus 1 day\n",
    "    * Removed the closed dates bc the data is not update beginning in august\n",
    "* A kwarg for the status will be added in aswell - This is for multivariate analysis\n",
    "    * For this kwarg, if the staus section is dropped then the open cases will be dropped too\n",
    "* This will be the dropping of certain columns such as incident_address\n",
    "* Investigate the outliers from the response times and handle them approproately\n",
    "    * Removed outliers\n",
    "* Discretizing the response time will also be added\n",
    "    * pdcut pandas generated bins and labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the close time for open requests to todays date plus 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_mac_data()\n",
    "\n",
    "# change columsn names to lower, remove the __c and that's it\n",
    "col_rename = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    col_rename[col] = col.lower().replace('__c', '').replace('date', '')\n",
    "\n",
    "col_rename['LASTMODIFIEDDATE'] = 'last_modified'\n",
    "\n",
    "df.rename(col_rename, axis=1, inplace = True)\n",
    "\n",
    "# changing multiple columns to date time dtype\n",
    "df[['created','last_modified', 'closed']] = df[['created','last_modified', 'closed']].apply(pd.to_datetime)\n",
    "\n",
    "# filling in the closeddate nulls with the date the furthest out\n",
    "df.closed.fillna(pd.to_datetime('today').normalize().tz_localize('US/Eastern'), inplace=True)\n",
    "\n",
    "df.closed.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop inicident address and change councli district to an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>township</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>council_district</th>\n",
       "      <th>created</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>closed</th>\n",
       "      <th>status</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illegal Dumping and Junk/Trash</td>\n",
       "      <td>Trash Accumulation or Dumped Materials</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2022-01-31 15:25:28+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>RequestIndy Mobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          keyword                             subcategory  \\\n",
       "0  Illegal Dumping and Junk/Trash  Trash Accumulation or Dumped Materials   \n",
       "\n",
       "  township          city    zip  council_district                   created  \\\n",
       "0    WAYNE  INDIANAPOLIS  46222              11.0 2022-01-31 15:25:28+00:00   \n",
       "\n",
       "              last_modified                    closed  status  \\\n",
       "0 2022-02-01 13:59:02+00:00 2022-02-01 13:59:02+00:00  Closed   \n",
       "\n",
       "               origin  \n",
       "0  RequestIndy Mobile  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding drop\n",
    "df.columns\n",
    "\n",
    "# dropping the unneeded columns\n",
    "df.drop(['objectid', 'casenumber', 'source_id', 'incident_address'], axis=1, inplace=True)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing council district dtype\n",
    "\n",
    "# drop nulls\n",
    "df = df.dropna()\n",
    "\n",
    "# changing the type to string object\n",
    "df['council_district'] = df.council_district.astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KWARG: status\n",
    "* becasue the most recent update for the data is from August - contacted the MAC service desk and sent an email to Information service Agency on Tuesday Aug 15 2023 for a year old issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 'drop'\n",
    "\n",
    "if status == 'drop':\n",
    "\n",
    "    df = df[df.status == 'Closed']\n",
    "\n",
    "    df.drop('status', axis=1, inplace=True)\n",
    "    \n",
    "elif status == 'keep':\n",
    "\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response time outliers and discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         882374\n",
       "mean      47 days 01:55:58.844139786\n",
       "std      208 days 14:47:12.869852328\n",
       "min                  0 days 00:00:00\n",
       "25%                  0 days 23:09:00\n",
       "50%           3 days 12:47:42.500000\n",
       "75%          10 days 07:20:16.750000\n",
       "max               2563 days 13:01:40\n",
       "Name: response_time, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         220594\n",
       "mean     180 days 10:24:01.978127240\n",
       "std      387 days 18:08:09.797427092\n",
       "min                 10 days 07:20:28\n",
       "25%          18 days 16:44:49.500000\n",
       "50%                 37 days 21:25:45\n",
       "75%         114 days 01:09:54.500000\n",
       "max               2563 days 13:01:40\n",
       "Name: response_time, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.response_time > df.response_time.quantile(.75)].response_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.response_time / pd.Timedelta(weeks=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        2022-01-31 15:25:28+00:00\n",
       " 1        2022-01-28 18:35:54+00:00\n",
       " 3        2022-01-30 21:23:42+00:00\n",
       " 4        2022-01-31 15:44:58+00:00\n",
       " 5        2022-01-30 22:37:17+00:00\n",
       "                     ...           \n",
       " 940633   2020-10-28 13:41:38+00:00\n",
       " 940634   2022-03-02 18:04:11+00:00\n",
       " 940635   2021-06-23 15:58:24+00:00\n",
       " 940636   2020-10-29 10:10:10+00:00\n",
       " 940637   2020-10-29 13:17:42+00:00\n",
       " Name: created, Length: 772962, dtype: datetime64[ns, UTC],\n",
       " 0        2022-02-01 13:59:02+00:00\n",
       " 1        2022-01-29 03:43:20+00:00\n",
       " 3        2022-02-03 21:29:59+00:00\n",
       " 4        2022-01-31 16:37:08+00:00\n",
       " 5        2022-02-03 22:44:59+00:00\n",
       "                     ...           \n",
       " 940633   2020-10-28 17:43:16+00:00\n",
       " 940634   2022-03-09 19:08:30+00:00\n",
       " 940635   2021-06-24 18:44:11+00:00\n",
       " 940636   2020-10-29 18:12:11+00:00\n",
       " 940637   2020-11-13 03:42:20+00:00\n",
       " Name: closed, Length: 772962, dtype: datetime64[ns, UTC])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['created'], df['closed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Interval(df['created'],\n",
    "# df['closed'], closed='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(df, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>township</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>council_district</th>\n",
       "      <th>created</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>closed</th>\n",
       "      <th>origin</th>\n",
       "      <th>response_time</th>\n",
       "      <th>response_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illegal Dumping and Junk/Trash</td>\n",
       "      <td>Trash Accumulation or Dumped Materials</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46222</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-01-31 15:25:28+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>RequestIndy Mobile</td>\n",
       "      <td>0 days 22:33:34</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          keyword                             subcategory  \\\n",
       "0  Illegal Dumping and Junk/Trash  Trash Accumulation or Dumped Materials   \n",
       "\n",
       "  township          city    zip council_district                   created  \\\n",
       "0    WAYNE  INDIANAPOLIS  46222               11 2022-01-31 15:25:28+00:00   \n",
       "\n",
       "              last_modified                    closed              origin  \\\n",
       "0 2022-02-01 13:59:02+00:00 2022-02-01 13:59:02+00:00  RequestIndy Mobile   \n",
       "\n",
       "    response_time response_rating  \n",
       "0 0 days 22:33:34       excellent  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['response_rating'] = pd.cut(df['response_time'], 5, labels=['excellent', 'great', 'good', 'fair','poor'])\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response_time\n",
       "(-1 days +23:04:48.418000, 7 days 15:58:36.400000]    625619\n",
       "(7 days 15:58:36.400000, 15 days 07:57:12.800000]      76319\n",
       "(15 days 07:57:12.800000, 22 days 23:55:49.200000]     33316\n",
       "(22 days 23:55:49.200000, 30 days 15:54:25.600000]     20377\n",
       "(30 days 15:54:25.600000, 38 days 07:53:02]            17331\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df['response_time'], 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        772962\n",
       "unique            5\n",
       "top       excellent\n",
       "freq         625619\n",
       "Name: response_rating, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response_rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>township</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>council_district</th>\n",
       "      <th>created</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>closed</th>\n",
       "      <th>origin</th>\n",
       "      <th>response_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illegal Dumping and Junk/Trash</td>\n",
       "      <td>Trash Accumulation or Dumped Materials</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46222</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-01-31 15:25:28+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>2022-02-01 13:59:02+00:00</td>\n",
       "      <td>RequestIndy Mobile</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46218</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-01-28 18:35:54+00:00</td>\n",
       "      <td>2022-01-29 03:43:27+00:00</td>\n",
       "      <td>2022-01-29 03:43:20+00:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>Street/Alley (ABV)</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46205</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-01-30 21:23:42+00:00</td>\n",
       "      <td>2022-02-03 21:29:59+00:00</td>\n",
       "      <td>2022-02-03 21:29:59+00:00</td>\n",
       "      <td>RequestIndy Online</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trash</td>\n",
       "      <td>96 Gal Trash (Missed)</td>\n",
       "      <td>LAWRENCE</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46226</td>\n",
       "      <td>13</td>\n",
       "      <td>2022-01-31 15:44:58+00:00</td>\n",
       "      <td>2022-01-31 16:37:08+00:00</td>\n",
       "      <td>2022-01-31 16:37:08+00:00</td>\n",
       "      <td>RequestIndy Online</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abandoned Vehicle</td>\n",
       "      <td>Street/Alley (ABV)</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46202</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-01-30 22:37:17+00:00</td>\n",
       "      <td>2022-02-03 22:44:59+00:00</td>\n",
       "      <td>2022-02-03 22:44:59+00:00</td>\n",
       "      <td>RequestIndy Online</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940633</th>\n",
       "      <td>Animal</td>\n",
       "      <td>Noise (Animal)</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46201</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-10-28 13:41:38+00:00</td>\n",
       "      <td>2020-10-28 17:43:21+00:00</td>\n",
       "      <td>2020-10-28 17:43:16+00:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940634</th>\n",
       "      <td>Chuckhole</td>\n",
       "      <td>Street (Chuckhole)</td>\n",
       "      <td>DECATUR</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46221</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-03-02 18:04:11+00:00</td>\n",
       "      <td>2022-03-09 19:08:30+00:00</td>\n",
       "      <td>2022-03-09 19:08:30+00:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940635</th>\n",
       "      <td>Weeds</td>\n",
       "      <td>Private Property (Complaint)</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46201</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-06-23 15:58:24+00:00</td>\n",
       "      <td>2021-06-24 18:44:11+00:00</td>\n",
       "      <td>2021-06-24 18:44:11+00:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940636</th>\n",
       "      <td>Debris/Litter</td>\n",
       "      <td>Debris in Alley/Street</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46208</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-10-29 10:10:10+00:00</td>\n",
       "      <td>2020-12-03 20:47:07+00:00</td>\n",
       "      <td>2020-10-29 18:12:11+00:00</td>\n",
       "      <td>RequestIndy Mobile</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940637</th>\n",
       "      <td>Trash</td>\n",
       "      <td>96 Gal Cart - Stolen</td>\n",
       "      <td>CENTER</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>46203</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-10-29 13:17:42+00:00</td>\n",
       "      <td>2020-11-13 03:42:20+00:00</td>\n",
       "      <td>2020-11-13 03:42:20+00:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772962 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               keyword  \\\n",
       "0       Illegal Dumping and Junk/Trash   \n",
       "1                               Animal   \n",
       "3                    Abandoned Vehicle   \n",
       "4                                Trash   \n",
       "5                    Abandoned Vehicle   \n",
       "...                                ...   \n",
       "940633                          Animal   \n",
       "940634                       Chuckhole   \n",
       "940635                           Weeds   \n",
       "940636                   Debris/Litter   \n",
       "940637                           Trash   \n",
       "\n",
       "                                   subcategory    township          city  \\\n",
       "0       Trash Accumulation or Dumped Materials       WAYNE  INDIANAPOLIS   \n",
       "1                                        Abuse      CENTER  INDIANAPOLIS   \n",
       "3                           Street/Alley (ABV)  WASHINGTON  INDIANAPOLIS   \n",
       "4                        96 Gal Trash (Missed)    LAWRENCE  INDIANAPOLIS   \n",
       "5                           Street/Alley (ABV)      CENTER  INDIANAPOLIS   \n",
       "...                                        ...         ...           ...   \n",
       "940633                          Noise (Animal)      CENTER  INDIANAPOLIS   \n",
       "940634                      Street (Chuckhole)     DECATUR  INDIANAPOLIS   \n",
       "940635            Private Property (Complaint)      CENTER  INDIANAPOLIS   \n",
       "940636                  Debris in Alley/Street      CENTER  INDIANAPOLIS   \n",
       "940637                    96 Gal Cart - Stolen      CENTER  INDIANAPOLIS   \n",
       "\n",
       "          zip council_district                   created  \\\n",
       "0       46222               11 2022-01-31 15:25:28+00:00   \n",
       "1       46218                9 2022-01-28 18:35:54+00:00   \n",
       "3       46205                9 2022-01-30 21:23:42+00:00   \n",
       "4       46226               13 2022-01-31 15:44:58+00:00   \n",
       "5       46202               11 2022-01-30 22:37:17+00:00   \n",
       "...       ...              ...                       ...   \n",
       "940633  46201               12 2020-10-28 13:41:38+00:00   \n",
       "940634  46221               20 2022-03-02 18:04:11+00:00   \n",
       "940635  46201               12 2021-06-23 15:58:24+00:00   \n",
       "940636  46208                9 2020-10-29 10:10:10+00:00   \n",
       "940637  46203               21 2020-10-29 13:17:42+00:00   \n",
       "\n",
       "                   last_modified                    closed  \\\n",
       "0      2022-02-01 13:59:02+00:00 2022-02-01 13:59:02+00:00   \n",
       "1      2022-01-29 03:43:27+00:00 2022-01-29 03:43:20+00:00   \n",
       "3      2022-02-03 21:29:59+00:00 2022-02-03 21:29:59+00:00   \n",
       "4      2022-01-31 16:37:08+00:00 2022-01-31 16:37:08+00:00   \n",
       "5      2022-02-03 22:44:59+00:00 2022-02-03 22:44:59+00:00   \n",
       "...                          ...                       ...   \n",
       "940633 2020-10-28 17:43:21+00:00 2020-10-28 17:43:16+00:00   \n",
       "940634 2022-03-09 19:08:30+00:00 2022-03-09 19:08:30+00:00   \n",
       "940635 2021-06-24 18:44:11+00:00 2021-06-24 18:44:11+00:00   \n",
       "940636 2020-12-03 20:47:07+00:00 2020-10-29 18:12:11+00:00   \n",
       "940637 2020-11-13 03:42:20+00:00 2020-11-13 03:42:20+00:00   \n",
       "\n",
       "                    origin response_rating  \n",
       "0       RequestIndy Mobile       excellent  \n",
       "1                    Phone       excellent  \n",
       "3       RequestIndy Online       excellent  \n",
       "4       RequestIndy Online       excellent  \n",
       "5       RequestIndy Online       excellent  \n",
       "...                    ...             ...  \n",
       "940633               Phone       excellent  \n",
       "940634               Phone       excellent  \n",
       "940635               Phone       excellent  \n",
       "940636  RequestIndy Mobile       excellent  \n",
       "940637               Phone           great  \n",
       "\n",
       "[772962 rows x 11 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('response_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "1         (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "3         (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "4         (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "5         (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "                                ...                        \n",
       "940633    (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "940634    (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "940635    (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "940636    (-1 days +23:04:48.418000, 7 days 15:58:36.400...\n",
       "940637    (7 days 15:58:36.400000, 15 days 07:57:12.800000]\n",
       "Length: 772962, dtype: category\n",
       "Categories (5, interval[timedelta64[ns], right]): [(-1 days +23:04:48.418000, 7 days 15:58:36.400... < (7 days 15:58:36.400000, 15 days 07:57:12.800000] < (15 days 07:57:12.800000, 22 days 23:55:49.200... < (22 days 23:55:49.200000, 30 days 15:54:25.600... < (30 days 15:54:25.600000, 38 days 07:53:02]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "* I think the response time ratings may need to be calculated based on the department, but this is something for later - put in the trello idra bank\n",
    "\n",
    "Note on reponse_levels:\n",
    "* (-1 days +23:04:48.418000, 7 days 15:58:36.400000]    625619\n",
    "* (7 days 15:58:36.400000, 15 days 07:57:12.800000]      76319\n",
    "* (15 days 07:57:12.800000, 22 days 23:55:49.200000]     33316\n",
    "* (2 days 23:55:49.200000, 30 days 15:54:25.600000]     20377\n",
    "* (0 days 15:54:25.600000, 38 days 07:53:02]            17331\n",
    "* Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, k=1.5):\n",
    "    '''\n",
    "    Actions: removies outliers using the IQR with a default k of 1.5\n",
    "    '''\n",
    "    # initialize dictionary\n",
    "    col_qs = {}\n",
    "    \n",
    "    # assign column names to variable\n",
    "    df_cols = df.columns\n",
    "    \n",
    "    # creates a list of column names\n",
    "    df_cols = df_cols.to_list()\n",
    "    \n",
    "    # remove cat cols\n",
    "    cat_cols = cat_cols = [col for col in df.columns if df[col].dtype == 'O']\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_cols.remove(col)\n",
    "\n",
    "    # for each column\n",
    "    for col in df_cols:\n",
    "        \n",
    "        # create qualtiles and put them in a dict\n",
    "        col_qs[col] = q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "\n",
    "    # for each col\n",
    "    for col in df_cols:    \n",
    "        \n",
    "        # calculate the iqr\n",
    "        iqr = col_qs[col][0.75] - col_qs[col][0.25]\n",
    "        \n",
    "        # calculate the lower fence\n",
    "        lower_fence = col_qs[col][0.25] - (iqr*k)\n",
    "        \n",
    "        # calculates the upper fence\n",
    "        upper_fence = col_qs[col][0.75] + (iqr*k)\n",
    "        \n",
    "        # remove outliers from df for each column\n",
    "        df = df[(df[col] > lower_fence) & (df[col] < upper_fence)]\n",
    "        \n",
    "    # exit df and return new df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_mac(status_focus = 'closed'):\n",
    "    '''\n",
    "    This function acquires mac data, renames columns, changes dtypes, fills in null values for the closed date, drops all other null values,\n",
    "    drops objectid, caseneumber, and source_id, and creates a new columns\n",
    "    KWARG: status_focus: 'closed' drops all open status cases and the status column\n",
    "    Modules:\n",
    "        from acquire import get_mac_data\n",
    "        import pandas as pd\n",
    "    '''\n",
    "    # get data\n",
    "    df = get_mac_data()\n",
    "\n",
    "    # change columsn names to lower, remove the __c and that's it\n",
    "    col_rename = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "       \n",
    "        col_rename[col] = col.lower().replace('__c', '').replace('date', '')\n",
    "\n",
    "    col_rename['LASTMODIFIEDDATE'] = 'last_modified'\n",
    "\n",
    "    df.rename(col_rename, axis=1, inplace = True)\n",
    "\n",
    "    # changing multiple columns to date time dtype\n",
    "    df[['created','last_modified', 'closed']] = df[['created','last_modified', 'closed']].apply(pd.to_datetime)\n",
    "\n",
    "    # dropping null values\n",
    "    # print(f'Dropping {df.shape[0] - df.dropna().shape[0]} rows')\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # KWARG if we only focus on closed status\n",
    "    if status_focus == 'closed':\n",
    "\n",
    "        # keep only closed status cases\n",
    "        df = df[df.status == 'Closed']\n",
    "\n",
    "        # and drop the status col bc no variance\n",
    "        df.drop('status', axis=1, inplace=True)    \n",
    "        \n",
    "    # KWARG if we want open - keep it the same\n",
    "    elif status_focus == 'open': \n",
    "    \n",
    "        pass\n",
    "\n",
    "    # dropping the unneeded columns\n",
    "    df.drop(['objectid', 'casenumber', 'source_id', 'incident_address'. 'last_modified'], axis=1, inplace=True)\n",
    "\n",
    "    # changing dtype to string object\n",
    "    df['council_district'] = df.council_district.astype(int).astype(str)\n",
    "    df['zip'] = df.zip.astype(str)\n",
    "\n",
    "    # adding the time from creation to closing\n",
    "    df['response_time'] = df['closed'] - df['created']\n",
    "    \n",
    "    # removing outliers\n",
    "    df = remove_outliers(df, k=3)\n",
    "    \n",
    "    # created the reponse rating\n",
    "    df['response_rating'] = pd.cut(df['response_time'], 5, labels=['excellent', 'great', 'good', 'fair','poor'])\n",
    "\n",
    "    # dropping time related columns\n",
    "    df.drop(['response_time', 'created', 'closed'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772962, 11)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_clean_mac()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removed from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the state\n",
    "# df['state'] = 'IN'\n",
    "\n",
    "# getting geocode format addresses\n",
    "# df['full_address'] = df['incident_address'] + ' ' +  df['city'] + ' ' + df['state'] + ' ' + df['zip'].astype(str)\n",
    "\n",
    "# filling in the closeddate nulls with the date the furthest out\n",
    "# df.closed.fillna(pd.to_datetime('today').normalize().tz_localize('US/Eastern'), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "* STATUS: is it useful to use the open status information? I don't think so\n",
    "\n",
    "#### Action:\n",
    "* Removing all open status claims\n",
    "    * The open status claims all have no closeddate which means we cannot use this data to train our model on. \n",
    "    * This data can be useful for the identifyinf which type of service requests are not handled for extedned periods of time, but that should be addressed in the the data already available unless there are some requests that have never closed even when introduced previosuly. That seems like a special case experience whoc deserves its own investigation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
